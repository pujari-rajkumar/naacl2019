{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import h5py\n",
    "import torch\n",
    "import torch._utils\n",
    "\n",
    "try:\n",
    "    torch._utils._rebuild_tensor_v2\n",
    "except AttributeError:\n",
    "    def _rebuild_tensor_v2(storage, storage_offset, size, stride, requires_grad, backward_hooks):\n",
    "        tensor = torch._utils._rebuild_tensor(storage, storage_offset, size, stride)\n",
    "        tensor.requires_grad = requires_grad\n",
    "        tensor._backward_hooks = backward_hooks\n",
    "        return tensor\n",
    "    torch._utils._rebuild_tensor_v2 = _rebuild_tensor_v2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "from models.baseline_snli import encoder\n",
    "from models.baseline_snli import binary_label_atten\n",
    "import argparse\n",
    "from models.snli_data import snli_data\n",
    "from models.snli_data import w2v\n",
    "from random import shuffle\n",
    "from models.baseline_snli import SeqAttnMatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = '/homes/rpujari/scratch/raj_qa/preprocess/data/multirc_bin-train.hdf5'\n",
    "dev_file = '/homes/rpujari/scratch/raj_qa/preprocess/data/st_bin-test.hdf5'\n",
    "test_file = '/homes/rpujari/scratch/raj_qa/preprocess/data/multirc_bin-val.hdf5'\n",
    "w2v_file = '/homes/rpujari/scratch/raj_qa/preprocess/data/glove.hdf5'\n",
    "log_dir = '/homes/rpujari/scratch/raj_qa/parikh_nli/trained_model/'\n",
    "log_fname = 'snli_bin_pred.log'\n",
    "gpu_id = 1\n",
    "embedding_size = 300\n",
    "epoch = 250\n",
    "dev_interval = 1\n",
    "optimizer ='Adagrad'\n",
    "Adagrad_init = 0.\n",
    "lr = 0.05\n",
    "hidden_size = 300\n",
    "max_length = -1\n",
    "display_interval = 1000\n",
    "max_grad_norm = 5\n",
    "para_init = 0.1\n",
    "weight_decay = 1e-5\n",
    "model_path = '/homes/rpujari/scratch/raj_qa/parikh_nli/trained_model/'\n",
    "trained_encoder = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_input-encoder.pt'\n",
    "trained_attn = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_inter-atten.pt'\n",
    "seq_attn = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_seq-atten.pt'\n",
    "input_optimizer = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_input-optimizer.pt'\n",
    "inter_atten_optimizer = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_inter-atten-optimizer.pt'\n",
    "seq_atten_optimizer = '/homes/rpujari/scratch/raj_qa/preprocess/saved_models/snli_bin_1_epoch-241_dev-acc-0.781_seq-atten-optimizer.pt' \n",
    "test_mode = True\n",
    "resume = False\n",
    "train_entailment = True\n",
    "train_contradiction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "train size # sent 113762\n",
      "train size # sent 113762\n",
      "train size # sent 113762\n",
      "train size # sent 113762\n",
      "train size # sent 113762\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "dev size # sent 9802\n",
      "dev size # sent 9802\n",
      "dev size # sent 9802\n",
      "dev size # sent 9802\n",
      "dev size # sent 9802\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "loading data...\n",
      "test size # sent 23285\n",
      "test size # sent 23285\n",
      "test size # sent 23285\n",
      "test size # sent 23285\n",
      "test size # sent 23285\n"
     ]
    }
   ],
   "source": [
    "if max_length < 0:\n",
    "    max_length = 9999\n",
    "\n",
    "# initialize the logger\n",
    "# create logger\n",
    "logger_name = \"mylog\"\n",
    "logger = logging.getLogger(logger_name)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# file handler\n",
    "fh = logging.FileHandler(log_dir + log_fname)\n",
    "fh.setLevel(logging.INFO)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# stream handler\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    "logger.addHandler(console)\n",
    "\n",
    "torch.cuda.set_device(gpu_id)\n",
    "\n",
    "#load train data\n",
    "logger.info('loading data...')\n",
    "train_data = snli_data(train_file, max_length)\n",
    "train_batches = train_data.batches\n",
    "train_id_batches = train_data.id_batches\n",
    "logger.info('train size # sent ' + str(train_data.size))\n",
    "\n",
    "# load test data\n",
    "logger.info('loading data...')\n",
    "dev_data = snli_data(dev_file, max_length)\n",
    "dev_batches = dev_data.batches\n",
    "dev_id_batches = dev_data.id_batches\n",
    "logger.info('dev size # sent ' + str(dev_data.size))\n",
    "\n",
    "# load test data\n",
    "logger.info('loading data...')\n",
    "test_data = snli_data(test_file, max_length)\n",
    "test_batches = test_data.batches\n",
    "test_id_batches = test_data.id_batches\n",
    "logger.info('test size # sent ' + str(test_data.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading input embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SeqAttnMatch (\n",
       "  (linear): Linear (300 -> 300)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get input embeddings\n",
    "logger.info('loading input embeddings...')\n",
    "word_vecs = w2v(w2v_file).word_vecs\n",
    "\n",
    "#loading trained model\n",
    "input_encoder = encoder(word_vecs.size()[0], embedding_size, hidden_size, para_init)\n",
    "input_encoder.embedding.weight.data.copy_(word_vecs)\n",
    "input_encoder.embedding.weight.requires_grad = False\n",
    "seq_atten = SeqAttnMatch(hidden_size, para_init)\n",
    "inter_atten = binary_label_atten(hidden_size, 2, para_init)\n",
    "\n",
    "input_encoder.cuda(gpu_id)\n",
    "inter_atten.cuda(gpu_id)\n",
    "seq_atten.cuda(gpu_id)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading trained model.\n",
      "loading trained model.\n",
      "loading trained model.\n",
      "loading trained model.\n",
      "loading trained model.\n"
     ]
    }
   ],
   "source": [
    "logger.info('loading trained model.')    \n",
    "input_encoder.load_state_dict(torch.load(trained_encoder, map_location={'cuda:0':'cuda:1'}))\n",
    "inter_atten.load_state_dict(torch.load(trained_attn, map_location={'cuda:0':'cuda:1'}))\n",
    "seq_atten.load_state_dict(torch.load(seq_attn, map_location={'cuda:0':'cuda:1'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/homes/rpujari/scratch/parikh_nli/preprocess/decomp-attn/data/snli.word.dict', 'r') as infile:\n",
    "    vocab_dict = {}\n",
    "    flines = infile.read().split('\\n')\n",
    "    for line in flines:\n",
    "        cols = line.split()\n",
    "        if len(cols) == 2:\n",
    "            vocab_dict[int(cols[1])] = cols[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12599.0, 7174.0, 3513.0, 0.0, 0.0, 0.1509, 0.0, 0.0, 1.0)\n",
      "Accuracy: 0.150863179593\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "input_encoder.eval()\n",
    "seq_atten.eval()\n",
    "inter_atten.eval()\n",
    "\n",
    "out_file = open(log_dir + 'test_out.txt', 'w') \n",
    "err_file = open(log_dir + 'test_err.txt', 'w')\n",
    "\n",
    "tot_corr = 0.0\n",
    "tot_eg = 0.0\n",
    "\n",
    "ent_c = 0.\n",
    "contr_c = 0.\n",
    "neu_c = 0.\n",
    "\n",
    "ent_pr = 0.\n",
    "contr_pr = 0.\n",
    "neu_pr = 0.\n",
    "\n",
    "ent_tot = 0.\n",
    "contr_tot = 0.\n",
    "neu_tot = 0.\n",
    "\n",
    "have_ques = test_data.have_ques\n",
    "have_ques = 0\n",
    "\n",
    "for i in range(len(test_batches)):\n",
    "    test_src_batch, test_tgt_batch, test_ques_batch, test_lbl_batch = test_batches[i]\n",
    "    test_src_ids, test_targ_ids = test_id_batches[i]\n",
    "\n",
    "    test_src_batch = Variable(test_src_batch.cuda(gpu_id))\n",
    "    test_tgt_batch = Variable(test_tgt_batch.cuda(gpu_id))\n",
    "    test_ques_batch = Variable(test_ques_batch.cuda(gpu_id))\n",
    "    test_lbl_batch = Variable(test_lbl_batch.cuda(gpu_id))\n",
    "\n",
    "    test_src_linear, test_tgt_linear, test_ques_linear=input_encoder(\n",
    "        test_src_batch, test_tgt_batch, test_ques_batch)\n",
    "\n",
    "    if have_ques == 1:\n",
    "        #Prepare masks\n",
    "        test_ques_mask = Variable(torch.from_numpy(np.zeros(test_ques_linear.data.shape[:2])).byte().cuda(gpu_id))\n",
    "        test_src_linear = seq_atten.forward(test_src_linear, test_ques_linear, test_ques_mask)\n",
    "        test_tgt_linear = seq_atten.forward(test_tgt_linear, test_ques_linear, test_ques_mask)\n",
    "\n",
    "    ent_prob, contr_prob = inter_atten(test_src_linear, test_tgt_linear)        \n",
    "\n",
    "    ent_probs = F.softmax(ent_prob)\n",
    "    contr_probs = F.softmax(contr_prob)\n",
    "\n",
    "    ent_prob, ent_pred = ent_probs.data.max(dim=1)\n",
    "    contr_prob, contr_pred = contr_probs.data.max(dim=1)\n",
    "    \n",
    "    tot_eg += test_lbl_batch.data.size()[0]\n",
    "    \n",
    "    for eg_num in range(len(ent_pred)):\n",
    "        \n",
    "        if debug:\n",
    "            sent = []\n",
    "            for idx in range(test_src_batch.data[eg_num].size()[0]):\n",
    "                sent.append(vocab_dict[test_src_batch.data[eg_num][idx] + 1])\n",
    "            t_sent = []\n",
    "            for idx in range(test_tgt_batch.data[eg_num].size()[0]):\n",
    "                t_sent.append(vocab_dict[test_tgt_batch.data[eg_num][idx] + 1])\n",
    "            q_sent = []\n",
    "            for idx in range(test_ques_batch.data[eg_num].size()[0]):\n",
    "                q_sent.append(vocab_dict[test_ques_batch.data[eg_num][idx] + 1])\n",
    "            print(' '.join(q_sent))\n",
    "            print(' '.join(sent))\n",
    "            print(' '.join(t_sent))\n",
    "            print(ent_pred[eg_num], contr_pred[eg_num], test_lbl_batch.data[eg_num][0], test_lbl_batch.data[eg_num][1])\n",
    "            print('\\n')\n",
    "        \n",
    "        if test_lbl_batch.data[eg_num][0] == 1 and test_lbl_batch.data[eg_num][1] == 0:\n",
    "            ent_tot += 1\n",
    "        elif test_lbl_batch.data[eg_num][0] == 0 and test_lbl_batch.data[eg_num][1] == 1:\n",
    "            contr_tot += 1\n",
    "        elif test_lbl_batch.data[eg_num][0] == 0 and test_lbl_batch.data[eg_num][1] == 0:\n",
    "            neu_tot += 1\n",
    "\n",
    "        if (ent_pred[eg_num] == test_lbl_batch.data[eg_num][0] or test_lbl_batch.data[eg_num][0] == -1) and\\\n",
    "           (contr_pred[eg_num] == test_lbl_batch.data[eg_num][1] or test_lbl_batch.data[eg_num][1] == -1):\n",
    "            tot_corr += 1.0\n",
    "            if ent_pred[eg_num] == 1 and contr_pred[eg_num] == 0:\n",
    "                ent_c += 1\n",
    "            elif ent_pred[eg_num] == 0 and contr_pred[eg_num] == 1:\n",
    "                contr_c += 1\n",
    "            elif ent_pred[eg_num] == 0 and contr_pred[eg_num] == 0:\n",
    "                neu_c += 1\n",
    "            else:\n",
    "                if ent_prob[eg_num] > contr_prob[eg_num]:\n",
    "                    ent_c += 1\n",
    "                else:\n",
    "                    contr_c += 1\n",
    "        else:\n",
    "            err_file.write(str(test_src_ids[eg_num]) + '\\t' + str(test_targ_ids[eg_num]) + '\\t' + str(ent_pred[eg_num]) + '\\t' + str(contr_pred[eg_num]) + str(test_lbl_batch[eg_num]) + '\\n')\n",
    "\n",
    "        if ent_pred[eg_num] == 1 and contr_pred[eg_num] == 0:\n",
    "            m_id = 0\n",
    "            m_prob = ent_prob[eg_num]\n",
    "            ent_pr += 1\n",
    "        elif ent_pred[eg_num] == 0 and contr_pred[eg_num] == 1:\n",
    "            m_id = 2\n",
    "            m_prob = contr_prob[eg_num]\n",
    "            contr_pr += 1\n",
    "        elif ent_pred[eg_num] == 0 and contr_pred[eg_num] == 0:\n",
    "            m_id = 1\n",
    "            m_prob = 1.0\n",
    "            neu_pr += 1\n",
    "        else:\n",
    "            if ent_prob[eg_num] > contr_prob[eg_num]:\n",
    "                m_id = 0\n",
    "                m_prob = ent_prob[eg_num]\n",
    "                ent_pr += 1\n",
    "            else:\n",
    "                m_id = 2\n",
    "                m_prob = contr_prob[eg_num]\n",
    "                contr_pr += 1\n",
    "        out_file.write(str(test_src_ids[eg_num]) + '\\t' + str(test_targ_ids[eg_num]) + '\\t' + str(m_prob) + '\\t' + str(m_id) + '\\n')\n",
    "\n",
    "out_file.close()\n",
    "err_file.close()\n",
    "print(ent_pr, contr_pr, neu_pr, round(ent_c/(ent_tot + 0.01), 4),\\\n",
    "      round(contr_c/(contr_tot  + 0.01), 4), round(neu_c/(neu_tot + 0.01), 4), \\\n",
    "     round((ent_c/(ent_pr + 0.01)), 4), round((contr_c/(contr_pr + 0.01)), 4), round((neu_c/(neu_pr + 0.01)), 4))\n",
    "print('Accuracy: '+ str(tot_corr / tot_eg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
